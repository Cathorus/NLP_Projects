{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ca3edd",
   "metadata": {
    "papermill": {
     "duration": 0.01555,
     "end_time": "2023-08-06T12:52:11.740077",
     "exception": false,
     "start_time": "2023-08-06T12:52:11.724527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. [Loading Data & Libraries](#1)\n",
    "1. [Text Processing](#2)\n",
    "1. [Build The Model](#3)\n",
    "1. [Testing Model](#4)\n",
    "1. [Model Training](#5)\n",
    "1. [Generate Text](#6)\n",
    "1. [Extra: Customized Training](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbe1808",
   "metadata": {
    "papermill": {
     "duration": 0.016453,
     "end_time": "2023-08-06T12:52:11.771717",
     "exception": false,
     "start_time": "2023-08-06T12:52:11.755264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id = \"1\"></a><br>\n",
    "# Loading Data & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53ed2dbc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:11.804592Z",
     "iopub.status.busy": "2023-08-06T12:52:11.804160Z",
     "iopub.status.idle": "2023-08-06T12:52:20.663268Z",
     "shell.execute_reply": "2023-08-06T12:52:20.662335Z"
    },
    "papermill": {
     "duration": 8.879339,
     "end_time": "2023-08-06T12:52:20.666129",
     "exception": false,
     "start_time": "2023-08-06T12:52:11.786790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e97191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:20.699782Z",
     "iopub.status.busy": "2023-08-06T12:52:20.698666Z",
     "iopub.status.idle": "2023-08-06T12:52:20.814012Z",
     "shell.execute_reply": "2023-08-06T12:52:20.812732Z"
    },
    "papermill": {
     "duration": 0.135054,
     "end_time": "2023-08-06T12:52:20.816846",
     "exception": false,
     "start_time": "2023-08-06T12:52:20.681792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1115394/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f47a3b3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:20.850386Z",
     "iopub.status.busy": "2023-08-06T12:52:20.849930Z",
     "iopub.status.idle": "2023-08-06T12:52:20.859360Z",
     "shell.execute_reply": "2023-08-06T12:52:20.858092Z"
    },
    "papermill": {
     "duration": 0.029365,
     "end_time": "2023-08-06T12:52:20.861870",
     "exception": false,
     "start_time": "2023-08-06T12:52:20.832505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a24a12fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:20.895533Z",
     "iopub.status.busy": "2023-08-06T12:52:20.895131Z",
     "iopub.status.idle": "2023-08-06T12:52:20.901104Z",
     "shell.execute_reply": "2023-08-06T12:52:20.899983Z"
    },
    "papermill": {
     "duration": 0.026385,
     "end_time": "2023-08-06T12:52:20.903995",
     "exception": false,
     "start_time": "2023-08-06T12:52:20.877610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "902dc011",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:20.937643Z",
     "iopub.status.busy": "2023-08-06T12:52:20.937244Z",
     "iopub.status.idle": "2023-08-06T12:52:20.964074Z",
     "shell.execute_reply": "2023-08-06T12:52:20.962979Z"
    },
    "papermill": {
     "duration": 0.046814,
     "end_time": "2023-08-06T12:52:20.966818",
     "exception": false,
     "start_time": "2023-08-06T12:52:20.920004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd003d84",
   "metadata": {
    "papermill": {
     "duration": 0.015899,
     "end_time": "2023-08-06T12:52:20.999006",
     "exception": false,
     "start_time": "2023-08-06T12:52:20.983107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id = \"2\"></a><br>\n",
    "# Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ba4b268",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:21.032640Z",
     "iopub.status.busy": "2023-08-06T12:52:21.032220Z",
     "iopub.status.idle": "2023-08-06T12:52:21.183491Z",
     "shell.execute_reply": "2023-08-06T12:52:21.182348Z"
    },
    "papermill": {
     "duration": 0.170871,
     "end_time": "2023-08-06T12:52:21.185936",
     "exception": false,
     "start_time": "2023-08-06T12:52:21.015065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ['abcdefg', 'xyz']\n",
    "\n",
    "chars = tf.strings.unicode_split(example, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9834137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:21.220560Z",
     "iopub.status.busy": "2023-08-06T12:52:21.220160Z",
     "iopub.status.idle": "2023-08-06T12:52:21.257790Z",
     "shell.execute_reply": "2023-08-06T12:52:21.256603Z"
    },
    "papermill": {
     "duration": 0.05765,
     "end_time": "2023-08-06T12:52:21.260412",
     "exception": false,
     "start_time": "2023-08-06T12:52:21.202762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1a61e6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:21.294636Z",
     "iopub.status.busy": "2023-08-06T12:52:21.293806Z",
     "iopub.status.idle": "2023-08-06T12:52:21.306723Z",
     "shell.execute_reply": "2023-08-06T12:52:21.305637Z"
    },
    "papermill": {
     "duration": 0.032457,
     "end_time": "2023-08-06T12:52:21.309028",
     "exception": false,
     "start_time": "2023-08-06T12:52:21.276571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e46b330",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:21.343096Z",
     "iopub.status.busy": "2023-08-06T12:52:21.342685Z",
     "iopub.status.idle": "2023-08-06T12:52:21.364179Z",
     "shell.execute_reply": "2023-08-06T12:52:21.363274Z"
    },
    "papermill": {
     "duration": 0.041559,
     "end_time": "2023-08-06T12:52:21.366781",
     "exception": false,
     "start_time": "2023-08-06T12:52:21.325222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2ca58d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:21.402479Z",
     "iopub.status.busy": "2023-08-06T12:52:21.402016Z",
     "iopub.status.idle": "2023-08-06T12:52:21.411483Z",
     "shell.execute_reply": "2023-08-06T12:52:21.410403Z"
    },
    "papermill": {
     "duration": 0.029402,
     "end_time": "2023-08-06T12:52:21.413802",
     "exception": false,
     "start_time": "2023-08-06T12:52:21.384400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e68a889",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:21.448495Z",
     "iopub.status.busy": "2023-08-06T12:52:21.447676Z",
     "iopub.status.idle": "2023-08-06T12:52:21.532278Z",
     "shell.execute_reply": "2023-08-06T12:52:21.531073Z"
    },
    "papermill": {
     "duration": 0.10488,
     "end_time": "2023-08-06T12:52:21.534848",
     "exception": false,
     "start_time": "2023-08-06T12:52:21.429968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'abcdefg', b'xyz'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join(chars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fba6820e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:21.569498Z",
     "iopub.status.busy": "2023-08-06T12:52:21.569080Z",
     "iopub.status.idle": "2023-08-06T12:52:21.574531Z",
     "shell.execute_reply": "2023-08-06T12:52:21.573437Z"
    },
    "papermill": {
     "duration": 0.025676,
     "end_time": "2023-08-06T12:52:21.576865",
     "exception": false,
     "start_time": "2023-08-06T12:52:21.551189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc117a2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:21.612020Z",
     "iopub.status.busy": "2023-08-06T12:52:21.611620Z",
     "iopub.status.idle": "2023-08-06T12:52:22.214511Z",
     "shell.execute_reply": "2023-08-06T12:52:22.213258Z"
    },
    "papermill": {
     "duration": 0.623191,
     "end_time": "2023-08-06T12:52:22.217002",
     "exception": false,
     "start_time": "2023-08-06T12:52:21.593811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e040b1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:22.253027Z",
     "iopub.status.busy": "2023-08-06T12:52:22.251857Z",
     "iopub.status.idle": "2023-08-06T12:52:22.331577Z",
     "shell.execute_reply": "2023-08-06T12:52:22.329976Z"
    },
    "papermill": {
     "duration": 0.100577,
     "end_time": "2023-08-06T12:52:22.334230",
     "exception": false,
     "start_time": "2023-08-06T12:52:22.233653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "C\n",
      "i\n",
      "t\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a49000e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:22.369141Z",
     "iopub.status.busy": "2023-08-06T12:52:22.368703Z",
     "iopub.status.idle": "2023-08-06T12:52:22.392813Z",
     "shell.execute_reply": "2023-08-06T12:52:22.391283Z"
    },
    "papermill": {
     "duration": 0.04441,
     "end_time": "2023-08-06T12:52:22.395150",
     "exception": false,
     "start_time": "2023-08-06T12:52:22.350740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
      " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
      " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
      " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
      " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
      " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
      " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
      " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "  print(chars_from_ids(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a31aa292",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:22.430916Z",
     "iopub.status.busy": "2023-08-06T12:52:22.430165Z",
     "iopub.status.idle": "2023-08-06T12:52:22.451493Z",
     "shell.execute_reply": "2023-08-06T12:52:22.450314Z"
    },
    "papermill": {
     "duration": 0.042015,
     "end_time": "2023-08-06T12:52:22.453930",
     "exception": false,
     "start_time": "2023-08-06T12:52:22.411915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
      "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
      "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
      "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "  print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "854cf948",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:22.489647Z",
     "iopub.status.busy": "2023-08-06T12:52:22.489222Z",
     "iopub.status.idle": "2023-08-06T12:52:22.497619Z",
     "shell.execute_reply": "2023-08-06T12:52:22.496392Z"
    },
    "papermill": {
     "duration": 0.029112,
     "end_time": "2023-08-06T12:52:22.499827",
     "exception": false,
     "start_time": "2023-08-06T12:52:22.470715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
       " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text\n",
    "split_input_target(list(\"Tensorflow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ede86f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:22.536516Z",
     "iopub.status.busy": "2023-08-06T12:52:22.535376Z",
     "iopub.status.idle": "2023-08-06T12:52:22.603529Z",
     "shell.execute_reply": "2023-08-06T12:52:22.602368Z"
    },
    "papermill": {
     "duration": 0.090058,
     "end_time": "2023-08-06T12:52:22.606878",
     "exception": false,
     "start_time": "2023-08-06T12:52:22.516820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdddabe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:22.643747Z",
     "iopub.status.busy": "2023-08-06T12:52:22.642967Z",
     "iopub.status.idle": "2023-08-06T12:52:22.696505Z",
     "shell.execute_reply": "2023-08-06T12:52:22.695176Z"
    },
    "papermill": {
     "duration": 0.074714,
     "end_time": "2023-08-06T12:52:22.699092",
     "exception": false,
     "start_time": "2023-08-06T12:52:22.624378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e71252e",
   "metadata": {
    "papermill": {
     "duration": 0.017038,
     "end_time": "2023-08-06T12:52:22.733445",
     "exception": false,
     "start_time": "2023-08-06T12:52:22.716407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id = \"3\"></a><br>\n",
    "# Build The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d13bff5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:22.769729Z",
     "iopub.status.busy": "2023-08-06T12:52:22.769306Z",
     "iopub.status.idle": "2023-08-06T12:52:22.785078Z",
     "shell.execute_reply": "2023-08-06T12:52:22.784102Z"
    },
    "papermill": {
     "duration": 0.036664,
     "end_time": "2023-08-06T12:52:22.787230",
     "exception": false,
     "start_time": "2023-08-06T12:52:22.750566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(30, 100), dtype=tf.int64, name=None), TensorSpec(shape=(30, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 30\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd85d263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:22.824333Z",
     "iopub.status.busy": "2023-08-06T12:52:22.823554Z",
     "iopub.status.idle": "2023-08-06T12:52:22.829846Z",
     "shell.execute_reply": "2023-08-06T12:52:22.829077Z"
    },
    "papermill": {
     "duration": 0.02716,
     "end_time": "2023-08-06T12:52:22.831990",
     "exception": false,
     "start_time": "2023-08-06T12:52:22.804830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc2f2b57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:22.868684Z",
     "iopub.status.busy": "2023-08-06T12:52:22.868165Z",
     "iopub.status.idle": "2023-08-06T12:52:22.877921Z",
     "shell.execute_reply": "2023-08-06T12:52:22.876909Z"
    },
    "papermill": {
     "duration": 0.03087,
     "end_time": "2023-08-06T12:52:22.880253",
     "exception": false,
     "start_time": "2023-08-06T12:52:22.849383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf498570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:22.916981Z",
     "iopub.status.busy": "2023-08-06T12:52:22.916573Z",
     "iopub.status.idle": "2023-08-06T12:52:22.945025Z",
     "shell.execute_reply": "2023-08-06T12:52:22.943991Z"
    },
    "papermill": {
     "duration": 0.050162,
     "end_time": "2023-08-06T12:52:22.947782",
     "exception": false,
     "start_time": "2023-08-06T12:52:22.897620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a600c0bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:22.984564Z",
     "iopub.status.busy": "2023-08-06T12:52:22.984126Z",
     "iopub.status.idle": "2023-08-06T12:52:25.549788Z",
     "shell.execute_reply": "2023-08-06T12:52:25.548515Z"
    },
    "papermill": {
     "duration": 2.587012,
     "end_time": "2023-08-06T12:52:25.552432",
     "exception": false,
     "start_time": "2023-08-06T12:52:22.965420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce6ad64d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:25.590744Z",
     "iopub.status.busy": "2023-08-06T12:52:25.589963Z",
     "iopub.status.idle": "2023-08-06T12:52:25.613388Z",
     "shell.execute_reply": "2023-08-06T12:52:25.612082Z"
    },
    "papermill": {
     "duration": 0.045284,
     "end_time": "2023-08-06T12:52:25.615672",
     "exception": false,
     "start_time": "2023-08-06T12:52:25.570388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  16896     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  107400    \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  6666      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 130,962\n",
      "Trainable params: 130,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dec232",
   "metadata": {
    "papermill": {
     "duration": 0.018385,
     "end_time": "2023-08-06T12:52:25.652902",
     "exception": false,
     "start_time": "2023-08-06T12:52:25.634517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id = \"4\"></a><br>\n",
    "# Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b75d61bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:25.693628Z",
     "iopub.status.busy": "2023-08-06T12:52:25.693140Z",
     "iopub.status.idle": "2023-08-06T12:52:25.706229Z",
     "shell.execute_reply": "2023-08-06T12:52:25.705380Z"
    },
    "papermill": {
     "duration": 0.036282,
     "end_time": "2023-08-06T12:52:25.708272",
     "exception": false,
     "start_time": "2023-08-06T12:52:25.671990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 52, 61, 26, 51, 32, 55, 37, 27, 12, 34,  2, 39,  1, 30, 46, 56,\n",
       "       28, 20, 30, 19, 28, 25, 53, 34, 39, 49, 20, 31, 61, 63, 15, 17, 46,\n",
       "        0, 57, 20, 23, 59,  3,  9, 17, 40, 27, 44, 59, 46, 32, 25, 63, 64,\n",
       "       23, 31,  3, 17, 44, 30, 45, 17, 64, 41, 27, 31, 43, 64, 43, 18, 21,\n",
       "        7, 24,  9, 62,  1, 15, 49, 57, 17, 43,  6, 59, 52, 14, 14, 26, 49,\n",
       "       34, 17, 63, 52, 41, 57,  0, 15, 21, 20, 64, 22, 24, 55,  9])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1072e92a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:25.748084Z",
     "iopub.status.busy": "2023-08-06T12:52:25.747057Z",
     "iopub.status.idle": "2023-08-06T12:52:25.760140Z",
     "shell.execute_reply": "2023-08-06T12:52:25.758657Z"
    },
    "papermill": {
     "duration": 0.035693,
     "end_time": "2023-08-06T12:52:25.762582",
     "exception": false,
     "start_time": "2023-08-06T12:52:25.726889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'rted by my jealousies\\nTo bloody thoughts and to revenge, I chose\\nCamillo for the minister to poison\\n'\n",
      "\n",
      "Next Char Predictions:\n",
      " b\"DmvMlSpXN;U Z\\nQgqOGQFOLnUZjGRvxBDg[UNK]rGJt!.DaNetgSLxyJR!DeQfDybNRdydEH,K.w\\nBjrDd'tmAAMjUDxmbr[UNK]BHGyIKp.\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30fed181",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:25.802956Z",
     "iopub.status.busy": "2023-08-06T12:52:25.802535Z",
     "iopub.status.idle": "2023-08-06T12:52:25.807768Z",
     "shell.execute_reply": "2023-08-06T12:52:25.806792Z"
    },
    "papermill": {
     "duration": 0.028456,
     "end_time": "2023-08-06T12:52:25.809788",
     "exception": false,
     "start_time": "2023-08-06T12:52:25.781332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2339244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:25.849097Z",
     "iopub.status.busy": "2023-08-06T12:52:25.848639Z",
     "iopub.status.idle": "2023-08-06T12:52:25.884156Z",
     "shell.execute_reply": "2023-08-06T12:52:25.882871Z"
    },
    "papermill": {
     "duration": 0.057964,
     "end_time": "2023-08-06T12:52:25.886528",
     "exception": false,
     "start_time": "2023-08-06T12:52:25.828564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (30, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.1856947, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "400bfb7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:25.926973Z",
     "iopub.status.busy": "2023-08-06T12:52:25.926580Z",
     "iopub.status.idle": "2023-08-06T12:52:25.935655Z",
     "shell.execute_reply": "2023-08-06T12:52:25.934377Z"
    },
    "papermill": {
     "duration": 0.032149,
     "end_time": "2023-08-06T12:52:25.938253",
     "exception": false,
     "start_time": "2023-08-06T12:52:25.906104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.73915"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "378bc34b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:25.978878Z",
     "iopub.status.busy": "2023-08-06T12:52:25.978476Z",
     "iopub.status.idle": "2023-08-06T12:52:25.999354Z",
     "shell.execute_reply": "2023-08-06T12:52:25.998149Z"
    },
    "papermill": {
     "duration": 0.0442,
     "end_time": "2023-08-06T12:52:26.002085",
     "exception": false,
     "start_time": "2023-08-06T12:52:25.957885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a763949",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:26.042797Z",
     "iopub.status.busy": "2023-08-06T12:52:26.041899Z",
     "iopub.status.idle": "2023-08-06T12:52:26.047473Z",
     "shell.execute_reply": "2023-08-06T12:52:26.046591Z"
    },
    "papermill": {
     "duration": 0.02828,
     "end_time": "2023-08-06T12:52:26.049593",
     "exception": false,
     "start_time": "2023-08-06T12:52:26.021313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f13c51",
   "metadata": {
    "papermill": {
     "duration": 0.018928,
     "end_time": "2023-08-06T12:52:26.087479",
     "exception": false,
     "start_time": "2023-08-06T12:52:26.068551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id = \"5\"></a><br>\n",
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2266638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:26.127887Z",
     "iopub.status.busy": "2023-08-06T12:52:26.127237Z",
     "iopub.status.idle": "2023-08-06T12:52:26.131556Z",
     "shell.execute_reply": "2023-08-06T12:52:26.130787Z"
    },
    "papermill": {
     "duration": 0.026651,
     "end_time": "2023-08-06T12:52:26.133611",
     "exception": false,
     "start_time": "2023-08-06T12:52:26.106960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2812cc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:52:26.173819Z",
     "iopub.status.busy": "2023-08-06T12:52:26.173103Z",
     "iopub.status.idle": "2023-08-06T13:04:15.890417Z",
     "shell.execute_reply": "2023-08-06T13:04:15.888730Z"
    },
    "papermill": {
     "duration": 709.740884,
     "end_time": "2023-08-06T13:04:15.893386",
     "exception": false,
     "start_time": "2023-08-06T12:52:26.152502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "368/368 [==============================] - 35s 83ms/step - loss: 2.5201\n",
      "Epoch 2/20\n",
      "368/368 [==============================] - 32s 83ms/step - loss: 1.9894\n",
      "Epoch 3/20\n",
      "368/368 [==============================] - 32s 83ms/step - loss: 1.8302\n",
      "Epoch 4/20\n",
      "368/368 [==============================] - 32s 83ms/step - loss: 1.7397\n",
      "Epoch 5/20\n",
      "368/368 [==============================] - 32s 83ms/step - loss: 1.6813\n",
      "Epoch 6/20\n",
      "368/368 [==============================] - 32s 83ms/step - loss: 1.6412\n",
      "Epoch 7/20\n",
      "368/368 [==============================] - 32s 83ms/step - loss: 1.6120\n",
      "Epoch 8/20\n",
      "368/368 [==============================] - 32s 83ms/step - loss: 1.5895\n",
      "Epoch 9/20\n",
      "368/368 [==============================] - 32s 84ms/step - loss: 1.5717\n",
      "Epoch 10/20\n",
      "368/368 [==============================] - 32s 84ms/step - loss: 1.5571\n",
      "Epoch 11/20\n",
      "368/368 [==============================] - 32s 83ms/step - loss: 1.5449\n",
      "Epoch 12/20\n",
      "368/368 [==============================] - 32s 84ms/step - loss: 1.5351\n",
      "Epoch 13/20\n",
      "368/368 [==============================] - 32s 83ms/step - loss: 1.5264\n",
      "Epoch 14/20\n",
      "368/368 [==============================] - 32s 83ms/step - loss: 1.5187\n",
      "Epoch 15/20\n",
      "368/368 [==============================] - 33s 84ms/step - loss: 1.5118\n",
      "Epoch 16/20\n",
      "368/368 [==============================] - 33s 84ms/step - loss: 1.5058\n",
      "Epoch 17/20\n",
      "368/368 [==============================] - 32s 83ms/step - loss: 1.5005\n",
      "Epoch 18/20\n",
      "368/368 [==============================] - 32s 83ms/step - loss: 1.4953\n",
      "Epoch 19/20\n",
      "368/368 [==============================] - 32s 83ms/step - loss: 1.4909\n",
      "Epoch 20/20\n",
      "368/368 [==============================] - 32s 83ms/step - loss: 1.4870\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eb3f78",
   "metadata": {
    "papermill": {
     "duration": 0.764939,
     "end_time": "2023-08-06T13:04:17.367945",
     "exception": false,
     "start_time": "2023-08-06T13:04:16.603006",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id = \"6\"></a><br>\n",
    "# Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18378380",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T13:04:18.753578Z",
     "iopub.status.busy": "2023-08-06T13:04:18.752574Z",
     "iopub.status.idle": "2023-08-06T13:04:18.766232Z",
     "shell.execute_reply": "2023-08-06T13:04:18.765401Z"
    },
    "papermill": {
     "duration": 0.707674,
     "end_time": "2023-08-06T13:04:18.768415",
     "exception": false,
     "start_time": "2023-08-06T13:04:18.060741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bc2bf04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T13:04:20.211887Z",
     "iopub.status.busy": "2023-08-06T13:04:20.211216Z",
     "iopub.status.idle": "2023-08-06T13:04:20.231186Z",
     "shell.execute_reply": "2023-08-06T13:04:20.230228Z"
    },
    "papermill": {
     "duration": 0.779223,
     "end_time": "2023-08-06T13:04:20.233743",
     "exception": false,
     "start_time": "2023-08-06T13:04:19.454520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e6bf396",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T13:04:21.613670Z",
     "iopub.status.busy": "2023-08-06T13:04:21.612793Z",
     "iopub.status.idle": "2023-08-06T13:04:23.835187Z",
     "shell.execute_reply": "2023-08-06T13:04:23.833443Z"
    },
    "papermill": {
     "duration": 2.916039,
     "end_time": "2023-08-06T13:04:23.837617",
     "exception": false,
     "start_time": "2023-08-06T13:04:20.921578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "Thus to way; for you hapse not therefore reverent, Camigd the find\n",
      "the fathers.\n",
      "\n",
      "ROMEO:\n",
      "While with-he will prescumptoon.\n",
      "\n",
      "LADY ANNE:\n",
      "Well, if thou do. Anone,\n",
      "A consues, but shall alook of him woild be rogute.\n",
      "Married, selas farsh'd me! my soul and of concertion, 'Swerance were, by good Cist: I am sweet.\n",
      "\n",
      "ANDOLISTUS:\n",
      "AhQuess of you, say very fontorming wite can step him, he sleep,\n",
      "Grengue\n",
      "For bied,\n",
      "Whether the love someted of yet his cowhian?\n",
      "\n",
      "PRINCE EDLETIO:\n",
      "O, become of the hows; are our green assuric, like their hasted littles being their to beatst it seater!\n",
      "\n",
      "CLIENER:\n",
      "To professiey, appose ye, and you see acquaint to\n",
      "are she shall formers. But Juliet consul, believe thee\n",
      "A breathe wnecs' heard arms; for God, the bain so wives us be the world: but thou may hast behold in Herry a fire you,\n",
      "Made my guest.\n",
      "This have tender the arives, bry angry dangerce?\n",
      "\n",
      "Second Camice fellow:\n",
      "The fuit him; yea therewax cusil.\n",
      "\n",
      "EXEVELLA:\n",
      "Agell for England,\n",
      "Distround\n",
      "And sweet foes are earth\n",
      "As deave my \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 2.210414171218872\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a11b4f68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T13:04:25.281420Z",
     "iopub.status.busy": "2023-08-06T13:04:25.280966Z",
     "iopub.status.idle": "2023-08-06T13:04:27.496220Z",
     "shell.execute_reply": "2023-08-06T13:04:27.495117Z"
    },
    "papermill": {
     "duration": 2.904804,
     "end_time": "2023-08-06T13:04:27.498744",
     "exception": false,
     "start_time": "2023-08-06T13:04:24.593940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b\"ROMEO:\\nBrother-rear'd queen doth no more to repant of this prince thou care?\\n\\nBAPTISTA:\\nBoth let uncounded\\nTo my good every coming my one, But was me not prayers.\\n\\nLEONTES:\\nNo, not Josy.\\n\\nMENENIUS:\\nWeld give entreatally, he spode angry by suncril o'ersituble's givenes faith\\nto be pash to break thou face?\\n\\nSEBASTIAN:\\nPasta't have done show if the oavens\\nThey fall death's may: he could shame, sirnce,\\nFor a hath his blot from them for the mores readless\\nbe gentlemen farred, cheer into the good my greet my knough unpresaying'll heavent of Henry.\\n\\nJOHNSO:\\nThat hour to your deedle, spite of your langman,\\nThat of answer it dovel.\\nWheir.\\n\\nQUEEN:\\nWhat thou pardard's in'tly,\\nOf men\\nIn all.\\n\\nPOLIXS:\\nOn, indeed\\nye, mark upon old,\\nTo the To these affect:\\nBut thou cape\\nTo harest to his intons myself.\\nMay like the mut to from thim; take discklese you are been out of a spoke yet, burnds are head ten:\\nNo roo their shall you gallen buss\\nOn the prince, sir I set unto thy woeth,\\nThat why set-reasure a trieen wh\"\n",
      " b\"ROMEO:\\nGives:\\nThough shake my sonstand\\nTo vasters\\nof him boin? Arfide least but matter, main see thy hand. Not worther dange wash thee suppress dissuf's love I should not of loven\\ngo may beasts. While stand. Comass me this heads to sworn will it is sound present putble been sturn, your sheplot gues chiphoner: I fellow she is doth Lordes to be arm that would nets,\\nIn Viscy\\nThe grace to go to lever!\\nAnd givener, and he seem:\\nFet battly is say it blood. Come, Warwick, fear\\nIs point welcome, and door arms\\nBe she's accoandlan;\\nfears,\\nAs it saking-show\\nMaster, but she he a gurpy friends stopp, no may milies and man it thou last for yet of good confersany advice though have the Ebyolds; and thou can, whose nate:\\nGo, his man duke up yours,\\nDie a doubt unourivenerous honest end forste turn the'e more have I lave shall mine bear'd.\\n\\nNORTHUMBRET:\\nWhat wood partos when it commonst sorn not though my foon for the after of my great littly arms and thy sent and some valsten country's wrongs\\nwho herans rona\"\n",
      " b\"ROMEO:\\nAn, hook be spewe there you seam lie;\\nWent Pegnes feeth his strong to the bitters it,\\nIf are eakes.\\n\\nBUCKINGHAM:\\nGood Matcress!\\n\\nGOCPMORESLOUS:\\nI'll days from hit thou eye against you bring all hat, you'll be agotess: Rome, and he to, or soist upon bidging brother you art your enstret time,\\nTo never as yet be grievest of friend Banising with my mavought! swiff thy content sworn'd not have not my louk an of the were follignices, if it say;\\nThat then Pe:\\nMost we have die, and the friends was tell.\\n\\nSICINIUS:\\nDivery.\\n\\nROMEO:\\nAnd thum the stast,\\nFire purmed, my age\\nbe truibled go deeds is heaven all my musicing.\\n\\nDether fellow look'd\\nor glant'd their art\\nTo quench dowing in the eads then goold things and her up your king, Io, if I should not\\nAnd kind, copure your gracious artly oen hath serve the sword's sort is by a fair just seem. Good see feart; and make a hand?\\nTello, why but selts in actor nastings to her heaven.\\n\\nHORTENSIO:\\nGoos most.\\n\\nSICINIUS:\\nOr not difes his father, how not look\"\n",
      " b\"ROMEO:\\nAnd deature! Kivelf a horse bite inswels, thy prifthin, I will with itsuran as as in Their bove\\nAn with no more pluck sworns as what not thou run walt,\\nToward, be bot the beand.\\n\\nKINA:\\nI think thou distret that thy Procking they are unranger\\nit honour him spud--\\nAway!\\n\\nThey holy busing in Cowincly, beast with the truth wan, if thou calling speaknes love of Hench the wians a unto this?\\n\\nAUTOLYCUS:\\nWhat you nowlame.\\n\\nBRUTUS:\\nHaw this point, beself; and I, and I am providiled much himself, need bearts: and thy mother, pool?\\nGost she to surse to be upon the stangeat ah her courmpraidness accertire you do not shall find\\nPaler death, O, thou be hearts night nool!\\nBe wazing tefret us, and, it subjolizened, give you lip of fares confoives! I wouldred friend's king the body to brick.\\n\\nGLOUCESTER:\\nWhat, done.\\n\\nCLAURENCE:\\nBeing stone. What place and coars and made agisulle in the voigeally musianot as sedies? Most shruds ality, more belly when thou disne'er, and make too\\nWhither life to be doubt\"\n",
      " b\"ROMEO:\\nAnd the own in your enceived in the time, and I, what this ever\\nEven'd believed love\\nAnthy, as by good for the sworn, thee a good majected: 'trace\\nWith men make then, my some us a furway.\\nWell, for Plueling;\\nAnd get more's vice told\\nTo harge; the repoint.\\n\\nHENRY BOLINGBROKE:\\nMy love your young away not bear this like sensoat, sir.\\n\\nJULIET:\\nSay, and regheit shusber time to chimpt to new emplest kind\\nWhose messick'd with,\\nthough twenty in Put of Bolingbroke melant to master; Plower, to you fits,\\nTake supant block,\\nIs incely forth to by thee!\\nWhy, shall say.\\n\\nLord Multisa dew'd on' head; comesor-villed his child! for my frimint are and breath,\\nAnd be us when Edward;\\nThat I have news having meakin; both reswer the thing whose gracious char eyes that\\nOf it all cousin forth the stary'ce to be doth pash;\\nIn not my prewipe: Besefcorties of remilt, poldant sell: there her in the give\\nFrom ben-hour is nothing you make ale:\\nI did her lacks, hew is the crown solfoinst content daged\\nWrit, but in a\"], shape=(5,), dtype=string) \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 2.2073287963867188\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result, '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3528088c",
   "metadata": {
    "papermill": {
     "duration": 0.689764,
     "end_time": "2023-08-06T13:04:28.880096",
     "exception": false,
     "start_time": "2023-08-06T13:04:28.190332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id = \"7\"></a><br>\n",
    "# Extra: Customized Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aed4a6c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T13:04:30.333020Z",
     "iopub.status.busy": "2023-08-06T13:04:30.331865Z",
     "iopub.status.idle": "2023-08-06T13:04:30.339258Z",
     "shell.execute_reply": "2023-08-06T13:04:30.338417Z"
    },
    "papermill": {
     "duration": 0.695345,
     "end_time": "2023-08-06T13:04:30.341559",
     "exception": false,
     "start_time": "2023-08-06T13:04:29.646214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomTraining(MyModel):\n",
    "  @tf.function\n",
    "  def train_step(self, inputs):\n",
    "      inputs, labels = inputs\n",
    "      with tf.GradientTape() as tape:\n",
    "          predictions = self(inputs, training=True)\n",
    "          loss = self.loss(labels, predictions)\n",
    "      grads = tape.gradient(loss, model.trainable_variables)\n",
    "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "      return {'loss': loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b50425a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T13:04:31.751169Z",
     "iopub.status.busy": "2023-08-06T13:04:31.750246Z",
     "iopub.status.idle": "2023-08-06T13:04:31.768850Z",
     "shell.execute_reply": "2023-08-06T13:04:31.767792Z"
    },
    "papermill": {
     "duration": 0.746693,
     "end_time": "2023-08-06T13:04:31.771536",
     "exception": false,
     "start_time": "2023-08-06T13:04:31.024843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CustomTraining(\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c3564c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T13:04:33.223662Z",
     "iopub.status.busy": "2023-08-06T13:04:33.222977Z",
     "iopub.status.idle": "2023-08-06T13:04:33.236818Z",
     "shell.execute_reply": "2023-08-06T13:04:33.235290Z"
    },
    "papermill": {
     "duration": 0.708124,
     "end_time": "2023-08-06T13:04:33.240419",
     "exception": false,
     "start_time": "2023-08-06T13:04:32.532295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9abb84a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T13:04:34.618875Z",
     "iopub.status.busy": "2023-08-06T13:04:34.618451Z",
     "iopub.status.idle": "2023-08-06T13:05:09.385903Z",
     "shell.execute_reply": "2023-08-06T13:05:09.384466Z"
    },
    "papermill": {
     "duration": 35.462133,
     "end_time": "2023-08-06T13:05:09.388264",
     "exception": false,
     "start_time": "2023-08-06T13:04:33.926131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 35s 84ms/step - loss: 2.5158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7989106d62f0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "950137ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T13:05:10.835441Z",
     "iopub.status.busy": "2023-08-06T13:05:10.835024Z",
     "iopub.status.idle": "2023-08-06T13:10:35.431652Z",
     "shell.execute_reply": "2023-08-06T13:10:35.430698Z"
    },
    "papermill": {
     "duration": 325.323932,
     "end_time": "2023-08-06T13:10:35.434483",
     "exception": false,
     "start_time": "2023-08-06T13:05:10.110551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.0751\n",
      "Epoch 1 Batch 50 Loss 2.0612\n",
      "Epoch 1 Batch 100 Loss 2.0480\n",
      "Epoch 1 Batch 150 Loss 2.0740\n",
      "Epoch 1 Batch 200 Loss 1.8980\n",
      "Epoch 1 Batch 250 Loss 1.9498\n",
      "Epoch 1 Batch 300 Loss 1.9100\n",
      "Epoch 1 Batch 350 Loss 1.9060\n",
      "\n",
      "Epoch 1 Loss: 1.9797\n",
      "Time taken for 1 epoch 33.06 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 2 Batch 0 Loss 1.8784\n",
      "Epoch 2 Batch 50 Loss 1.8797\n",
      "Epoch 2 Batch 100 Loss 1.8273\n",
      "Epoch 2 Batch 150 Loss 1.7824\n",
      "Epoch 2 Batch 200 Loss 1.8335\n",
      "Epoch 2 Batch 250 Loss 1.7618\n",
      "Epoch 2 Batch 300 Loss 1.7721\n",
      "Epoch 2 Batch 350 Loss 1.7972\n",
      "\n",
      "Epoch 2 Loss: 1.8158\n",
      "Time taken for 1 epoch 32.33 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 3 Batch 0 Loss 1.7596\n",
      "Epoch 3 Batch 50 Loss 1.7394\n",
      "Epoch 3 Batch 100 Loss 1.7115\n",
      "Epoch 3 Batch 150 Loss 1.7864\n",
      "Epoch 3 Batch 200 Loss 1.7072\n",
      "Epoch 3 Batch 250 Loss 1.7682\n",
      "Epoch 3 Batch 300 Loss 1.7406\n",
      "Epoch 3 Batch 350 Loss 1.7003\n",
      "\n",
      "Epoch 3 Loss: 1.7237\n",
      "Time taken for 1 epoch 32.08 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 4 Batch 0 Loss 1.6675\n",
      "Epoch 4 Batch 50 Loss 1.6629\n",
      "Epoch 4 Batch 100 Loss 1.7042\n",
      "Epoch 4 Batch 150 Loss 1.6161\n",
      "Epoch 4 Batch 200 Loss 1.7266\n",
      "Epoch 4 Batch 250 Loss 1.6393\n",
      "Epoch 4 Batch 300 Loss 1.6591\n",
      "Epoch 4 Batch 350 Loss 1.6177\n",
      "\n",
      "Epoch 4 Loss: 1.6663\n",
      "Time taken for 1 epoch 32.07 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 5 Batch 0 Loss 1.6322\n",
      "Epoch 5 Batch 50 Loss 1.6674\n",
      "Epoch 5 Batch 100 Loss 1.6247\n",
      "Epoch 5 Batch 150 Loss 1.5677\n",
      "Epoch 5 Batch 200 Loss 1.6985\n",
      "Epoch 5 Batch 250 Loss 1.6387\n",
      "Epoch 5 Batch 300 Loss 1.6329\n",
      "Epoch 5 Batch 350 Loss 1.5130\n",
      "\n",
      "Epoch 5 Loss: 1.6265\n",
      "Time taken for 1 epoch 32.16 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 6 Batch 0 Loss 1.6194\n",
      "Epoch 6 Batch 50 Loss 1.6741\n",
      "Epoch 6 Batch 100 Loss 1.5673\n",
      "Epoch 6 Batch 150 Loss 1.6270\n",
      "Epoch 6 Batch 200 Loss 1.5648\n",
      "Epoch 6 Batch 250 Loss 1.5887\n",
      "Epoch 6 Batch 300 Loss 1.6272\n",
      "Epoch 6 Batch 350 Loss 1.5671\n",
      "\n",
      "Epoch 6 Loss: 1.5973\n",
      "Time taken for 1 epoch 32.37 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 7 Batch 0 Loss 1.5614\n",
      "Epoch 7 Batch 50 Loss 1.5461\n",
      "Epoch 7 Batch 100 Loss 1.5758\n",
      "Epoch 7 Batch 150 Loss 1.5908\n",
      "Epoch 7 Batch 200 Loss 1.5709\n",
      "Epoch 7 Batch 250 Loss 1.5693\n",
      "Epoch 7 Batch 300 Loss 1.5679\n",
      "Epoch 7 Batch 350 Loss 1.5380\n",
      "\n",
      "Epoch 7 Loss: 1.5750\n",
      "Time taken for 1 epoch 32.58 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 8 Batch 0 Loss 1.5330\n",
      "Epoch 8 Batch 50 Loss 1.5804\n",
      "Epoch 8 Batch 100 Loss 1.5689\n",
      "Epoch 8 Batch 150 Loss 1.5846\n",
      "Epoch 8 Batch 200 Loss 1.5749\n",
      "Epoch 8 Batch 250 Loss 1.5566\n",
      "Epoch 8 Batch 300 Loss 1.5482\n",
      "Epoch 8 Batch 350 Loss 1.6071\n",
      "\n",
      "Epoch 8 Loss: 1.5571\n",
      "Time taken for 1 epoch 32.39 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 9 Batch 0 Loss 1.5369\n",
      "Epoch 9 Batch 50 Loss 1.5398\n",
      "Epoch 9 Batch 100 Loss 1.5345\n",
      "Epoch 9 Batch 150 Loss 1.5421\n",
      "Epoch 9 Batch 200 Loss 1.5466\n",
      "Epoch 9 Batch 250 Loss 1.5290\n",
      "Epoch 9 Batch 300 Loss 1.5585\n",
      "Epoch 9 Batch 350 Loss 1.5457\n",
      "\n",
      "Epoch 9 Loss: 1.5423\n",
      "Time taken for 1 epoch 32.70 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 10 Batch 0 Loss 1.4968\n",
      "Epoch 10 Batch 50 Loss 1.5286\n",
      "Epoch 10 Batch 100 Loss 1.4864\n",
      "Epoch 10 Batch 150 Loss 1.6264\n",
      "Epoch 10 Batch 200 Loss 1.5642\n",
      "Epoch 10 Batch 250 Loss 1.5595\n",
      "Epoch 10 Batch 300 Loss 1.5398\n",
      "Epoch 10 Batch 350 Loss 1.5604\n",
      "\n",
      "Epoch 10 Loss: 1.5298\n",
      "Time taken for 1 epoch 32.83 sec\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "mean = tf.metrics.Mean()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    mean.reset_states()\n",
    "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
    "        logs = model.train_step([inp, target])\n",
    "        mean.update_state(logs['loss'])\n",
    "\n",
    "        if batch_n % 50 == 0:\n",
    "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
    "            print(template)\n",
    "\n",
    "    # saving (checkpoint) the model every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
    "\n",
    "    print()\n",
    "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
    "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
    "    print(\"_\"*80)\n",
    "\n",
    "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1119.647936,
   "end_time": "2023-08-06T13:10:38.908689",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-06T12:51:59.260753",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
