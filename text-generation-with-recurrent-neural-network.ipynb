{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32362b98",
   "metadata": {
    "papermill": {
     "duration": 0.009886,
     "end_time": "2023-08-06T12:28:55.109960",
     "exception": false,
     "start_time": "2023-08-06T12:28:55.100074",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. [Loading Data & Libraries](#1)\n",
    "1. [Text Processing](#2)\n",
    "1. [Build The Model](#3)\n",
    "1. [Testing Model](#4)\n",
    "1. [Model Training](#5)\n",
    "1. [Extra: Customized Training](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdf2d5d",
   "metadata": {
    "papermill": {
     "duration": 0.010702,
     "end_time": "2023-08-06T12:28:55.130210",
     "exception": false,
     "start_time": "2023-08-06T12:28:55.119508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id = \"1\"></a><br>\n",
    "# Loading Data & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61579ca2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-06T12:28:55.151163Z",
     "iopub.status.busy": "2023-08-06T12:28:55.150759Z",
     "iopub.status.idle": "2023-08-06T12:29:05.046419Z",
     "shell.execute_reply": "2023-08-06T12:29:05.044887Z"
    },
    "papermill": {
     "duration": 9.909423,
     "end_time": "2023-08-06T12:29:05.049007",
     "exception": false,
     "start_time": "2023-08-06T12:28:55.139584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c43c15ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:05.070942Z",
     "iopub.status.busy": "2023-08-06T12:29:05.070146Z",
     "iopub.status.idle": "2023-08-06T12:29:05.665741Z",
     "shell.execute_reply": "2023-08-06T12:29:05.664805Z"
    },
    "papermill": {
     "duration": 0.609195,
     "end_time": "2023-08-06T12:29:05.668087",
     "exception": false,
     "start_time": "2023-08-06T12:29:05.058892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1115394/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f60e78d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:05.690568Z",
     "iopub.status.busy": "2023-08-06T12:29:05.689706Z",
     "iopub.status.idle": "2023-08-06T12:29:05.695990Z",
     "shell.execute_reply": "2023-08-06T12:29:05.695066Z"
    },
    "papermill": {
     "duration": 0.019408,
     "end_time": "2023-08-06T12:29:05.697851",
     "exception": false,
     "start_time": "2023-08-06T12:29:05.678443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036a5091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:05.720363Z",
     "iopub.status.busy": "2023-08-06T12:29:05.719798Z",
     "iopub.status.idle": "2023-08-06T12:29:05.724707Z",
     "shell.execute_reply": "2023-08-06T12:29:05.723575Z"
    },
    "papermill": {
     "duration": 0.01839,
     "end_time": "2023-08-06T12:29:05.726651",
     "exception": false,
     "start_time": "2023-08-06T12:29:05.708261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e73f54e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:05.749723Z",
     "iopub.status.busy": "2023-08-06T12:29:05.748271Z",
     "iopub.status.idle": "2023-08-06T12:29:05.773618Z",
     "shell.execute_reply": "2023-08-06T12:29:05.772315Z"
    },
    "papermill": {
     "duration": 0.038946,
     "end_time": "2023-08-06T12:29:05.775865",
     "exception": false,
     "start_time": "2023-08-06T12:29:05.736919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a160dd2",
   "metadata": {
    "papermill": {
     "duration": 0.010427,
     "end_time": "2023-08-06T12:29:05.796990",
     "exception": false,
     "start_time": "2023-08-06T12:29:05.786563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id = \"2\"></a><br>\n",
    "# Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf3a918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:05.820233Z",
     "iopub.status.busy": "2023-08-06T12:29:05.819696Z",
     "iopub.status.idle": "2023-08-06T12:29:05.983584Z",
     "shell.execute_reply": "2023-08-06T12:29:05.982126Z"
    },
    "papermill": {
     "duration": 0.178274,
     "end_time": "2023-08-06T12:29:05.985984",
     "exception": false,
     "start_time": "2023-08-06T12:29:05.807710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ['abcdefg', 'xyz']\n",
    "\n",
    "chars = tf.strings.unicode_split(example, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a80bf443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:06.009425Z",
     "iopub.status.busy": "2023-08-06T12:29:06.009065Z",
     "iopub.status.idle": "2023-08-06T12:29:06.049466Z",
     "shell.execute_reply": "2023-08-06T12:29:06.048141Z"
    },
    "papermill": {
     "duration": 0.054956,
     "end_time": "2023-08-06T12:29:06.052119",
     "exception": false,
     "start_time": "2023-08-06T12:29:05.997163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e903b27b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:06.075143Z",
     "iopub.status.busy": "2023-08-06T12:29:06.074772Z",
     "iopub.status.idle": "2023-08-06T12:29:06.087198Z",
     "shell.execute_reply": "2023-08-06T12:29:06.086094Z"
    },
    "papermill": {
     "duration": 0.026544,
     "end_time": "2023-08-06T12:29:06.089308",
     "exception": false,
     "start_time": "2023-08-06T12:29:06.062764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91667273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:06.112961Z",
     "iopub.status.busy": "2023-08-06T12:29:06.111961Z",
     "iopub.status.idle": "2023-08-06T12:29:06.132299Z",
     "shell.execute_reply": "2023-08-06T12:29:06.131431Z"
    },
    "papermill": {
     "duration": 0.034448,
     "end_time": "2023-08-06T12:29:06.134389",
     "exception": false,
     "start_time": "2023-08-06T12:29:06.099941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edd65d26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:06.157828Z",
     "iopub.status.busy": "2023-08-06T12:29:06.156371Z",
     "iopub.status.idle": "2023-08-06T12:29:06.167315Z",
     "shell.execute_reply": "2023-08-06T12:29:06.165935Z"
    },
    "papermill": {
     "duration": 0.024363,
     "end_time": "2023-08-06T12:29:06.169283",
     "exception": false,
     "start_time": "2023-08-06T12:29:06.144920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32cb1253",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:06.195630Z",
     "iopub.status.busy": "2023-08-06T12:29:06.194975Z",
     "iopub.status.idle": "2023-08-06T12:29:06.291943Z",
     "shell.execute_reply": "2023-08-06T12:29:06.290451Z"
    },
    "papermill": {
     "duration": 0.114374,
     "end_time": "2023-08-06T12:29:06.294608",
     "exception": false,
     "start_time": "2023-08-06T12:29:06.180234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'abcdefg', b'xyz'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join(chars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d028c43b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:06.318276Z",
     "iopub.status.busy": "2023-08-06T12:29:06.317842Z",
     "iopub.status.idle": "2023-08-06T12:29:06.323361Z",
     "shell.execute_reply": "2023-08-06T12:29:06.321947Z"
    },
    "papermill": {
     "duration": 0.020283,
     "end_time": "2023-08-06T12:29:06.325915",
     "exception": false,
     "start_time": "2023-08-06T12:29:06.305632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75ab8e5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:06.349759Z",
     "iopub.status.busy": "2023-08-06T12:29:06.349398Z",
     "iopub.status.idle": "2023-08-06T12:29:06.654074Z",
     "shell.execute_reply": "2023-08-06T12:29:06.652654Z"
    },
    "papermill": {
     "duration": 0.319195,
     "end_time": "2023-08-06T12:29:06.656310",
     "exception": false,
     "start_time": "2023-08-06T12:29:06.337115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b609c03d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:06.679781Z",
     "iopub.status.busy": "2023-08-06T12:29:06.679377Z",
     "iopub.status.idle": "2023-08-06T12:29:06.761829Z",
     "shell.execute_reply": "2023-08-06T12:29:06.760982Z"
    },
    "papermill": {
     "duration": 0.096884,
     "end_time": "2023-08-06T12:29:06.764176",
     "exception": false,
     "start_time": "2023-08-06T12:29:06.667292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "C\n",
      "i\n",
      "t\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4b4fbe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:06.788204Z",
     "iopub.status.busy": "2023-08-06T12:29:06.787652Z",
     "iopub.status.idle": "2023-08-06T12:29:06.806912Z",
     "shell.execute_reply": "2023-08-06T12:29:06.805928Z"
    },
    "papermill": {
     "duration": 0.03372,
     "end_time": "2023-08-06T12:29:06.808903",
     "exception": false,
     "start_time": "2023-08-06T12:29:06.775183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
      " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
      " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
      " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
      " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
      " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
      " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
      " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "  print(chars_from_ids(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dc545fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:06.832829Z",
     "iopub.status.busy": "2023-08-06T12:29:06.832246Z",
     "iopub.status.idle": "2023-08-06T12:29:06.851332Z",
     "shell.execute_reply": "2023-08-06T12:29:06.850008Z"
    },
    "papermill": {
     "duration": 0.0337,
     "end_time": "2023-08-06T12:29:06.853628",
     "exception": false,
     "start_time": "2023-08-06T12:29:06.819928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
      "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
      "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
      "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "  print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61bab6c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:06.878261Z",
     "iopub.status.busy": "2023-08-06T12:29:06.877879Z",
     "iopub.status.idle": "2023-08-06T12:29:06.885700Z",
     "shell.execute_reply": "2023-08-06T12:29:06.884601Z"
    },
    "papermill": {
     "duration": 0.022247,
     "end_time": "2023-08-06T12:29:06.887697",
     "exception": false,
     "start_time": "2023-08-06T12:29:06.865450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
       " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text\n",
    "split_input_target(list(\"Tensorflow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0470a712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:06.912474Z",
     "iopub.status.busy": "2023-08-06T12:29:06.911503Z",
     "iopub.status.idle": "2023-08-06T12:29:06.966230Z",
     "shell.execute_reply": "2023-08-06T12:29:06.964405Z"
    },
    "papermill": {
     "duration": 0.069691,
     "end_time": "2023-08-06T12:29:06.968741",
     "exception": false,
     "start_time": "2023-08-06T12:29:06.899050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "998fb9df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:06.992362Z",
     "iopub.status.busy": "2023-08-06T12:29:06.992019Z",
     "iopub.status.idle": "2023-08-06T12:29:07.031221Z",
     "shell.execute_reply": "2023-08-06T12:29:07.029930Z"
    },
    "papermill": {
     "duration": 0.053831,
     "end_time": "2023-08-06T12:29:07.033692",
     "exception": false,
     "start_time": "2023-08-06T12:29:06.979861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534efb20",
   "metadata": {
    "papermill": {
     "duration": 0.011089,
     "end_time": "2023-08-06T12:29:07.056873",
     "exception": false,
     "start_time": "2023-08-06T12:29:07.045784",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id = \"3\"></a><br>\n",
    "# Build The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ee3d592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:07.082566Z",
     "iopub.status.busy": "2023-08-06T12:29:07.080468Z",
     "iopub.status.idle": "2023-08-06T12:29:07.097640Z",
     "shell.execute_reply": "2023-08-06T12:29:07.096904Z"
    },
    "papermill": {
     "duration": 0.031364,
     "end_time": "2023-08-06T12:29:07.099411",
     "exception": false,
     "start_time": "2023-08-06T12:29:07.068047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(30, 100), dtype=tf.int64, name=None), TensorSpec(shape=(30, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 30\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9916c49b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:07.124680Z",
     "iopub.status.busy": "2023-08-06T12:29:07.124250Z",
     "iopub.status.idle": "2023-08-06T12:29:07.130806Z",
     "shell.execute_reply": "2023-08-06T12:29:07.128933Z"
    },
    "papermill": {
     "duration": 0.021558,
     "end_time": "2023-08-06T12:29:07.133047",
     "exception": false,
     "start_time": "2023-08-06T12:29:07.111489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2553554f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:07.157174Z",
     "iopub.status.busy": "2023-08-06T12:29:07.156845Z",
     "iopub.status.idle": "2023-08-06T12:29:07.164196Z",
     "shell.execute_reply": "2023-08-06T12:29:07.162927Z"
    },
    "papermill": {
     "duration": 0.022181,
     "end_time": "2023-08-06T12:29:07.166777",
     "exception": false,
     "start_time": "2023-08-06T12:29:07.144596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fce4d5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:07.191165Z",
     "iopub.status.busy": "2023-08-06T12:29:07.190813Z",
     "iopub.status.idle": "2023-08-06T12:29:07.219246Z",
     "shell.execute_reply": "2023-08-06T12:29:07.218118Z"
    },
    "papermill": {
     "duration": 0.043099,
     "end_time": "2023-08-06T12:29:07.221348",
     "exception": false,
     "start_time": "2023-08-06T12:29:07.178249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5ac75da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:07.246126Z",
     "iopub.status.busy": "2023-08-06T12:29:07.245139Z",
     "iopub.status.idle": "2023-08-06T12:29:08.865556Z",
     "shell.execute_reply": "2023-08-06T12:29:08.864187Z"
    },
    "papermill": {
     "duration": 1.635334,
     "end_time": "2023-08-06T12:29:08.868135",
     "exception": false,
     "start_time": "2023-08-06T12:29:07.232801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "304989ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:08.892136Z",
     "iopub.status.busy": "2023-08-06T12:29:08.891776Z",
     "iopub.status.idle": "2023-08-06T12:29:08.915546Z",
     "shell.execute_reply": "2023-08-06T12:29:08.914170Z"
    },
    "papermill": {
     "duration": 0.03853,
     "end_time": "2023-08-06T12:29:08.917955",
     "exception": false,
     "start_time": "2023-08-06T12:29:08.879425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  16896     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  107400    \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  6666      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 130,962\n",
      "Trainable params: 130,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ca24a1",
   "metadata": {
    "papermill": {
     "duration": 0.012086,
     "end_time": "2023-08-06T12:29:08.943709",
     "exception": false,
     "start_time": "2023-08-06T12:29:08.931623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id = \"4\"></a><br>\n",
    "# Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ff83e0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:08.969757Z",
     "iopub.status.busy": "2023-08-06T12:29:08.969406Z",
     "iopub.status.idle": "2023-08-06T12:29:08.980786Z",
     "shell.execute_reply": "2023-08-06T12:29:08.979875Z"
    },
    "papermill": {
     "duration": 0.026632,
     "end_time": "2023-08-06T12:29:08.982543",
     "exception": false,
     "start_time": "2023-08-06T12:29:08.955911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22, 21,  1, 32, 62, 52, 64, 12, 55, 35, 49,  9, 40, 17, 19, 18, 18,\n",
       "       57, 15, 33, 41, 17, 10, 14, 29, 39, 34, 37, 17, 19, 33, 14, 23, 36,\n",
       "       17, 30, 57, 12, 11, 22, 56, 11, 15,  3, 11, 62, 11, 47, 15, 31, 20,\n",
       "       61, 49, 10, 58, 40, 34, 51, 24, 21, 54, 29, 19, 15, 11, 60, 54, 19,\n",
       "       36, 15,  5, 24, 13, 30,  7, 59, 39, 36, 32, 19, 16, 23,  3, 58, 49,\n",
       "       65, 26, 54, 43, 62, 34, 37, 61, 47, 52, 25,  9, 14, 50, 12])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2117b3c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:09.008776Z",
     "iopub.status.busy": "2023-08-06T12:29:09.008402Z",
     "iopub.status.idle": "2023-08-06T12:29:09.019632Z",
     "shell.execute_reply": "2023-08-06T12:29:09.018755Z"
    },
    "papermill": {
     "duration": 0.02666,
     "end_time": "2023-08-06T12:29:09.021590",
     "exception": false,
     "start_time": "2023-08-06T12:29:08.994930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'ak off the parley; for scarce I can refrain\\nThe execution of my big-swoln heart\\nUpon that Clifford, '\n",
      "\n",
      "Next Char Predictions:\n",
      " b'IH\\nSwmy;pVj.aDFEErBTbD3APZUXDFTAJWDQr;:Iq:B!:w:hBRGvj3saUlKHoPFB:uoFWB&K?Q,tZWSFCJ!sjzModwUXvhmL.Ak;'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba9e7b9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:09.047976Z",
     "iopub.status.busy": "2023-08-06T12:29:09.047351Z",
     "iopub.status.idle": "2023-08-06T12:29:09.051977Z",
     "shell.execute_reply": "2023-08-06T12:29:09.051005Z"
    },
    "papermill": {
     "duration": 0.0198,
     "end_time": "2023-08-06T12:29:09.053746",
     "exception": false,
     "start_time": "2023-08-06T12:29:09.033946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e69c5cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:09.080698Z",
     "iopub.status.busy": "2023-08-06T12:29:09.079427Z",
     "iopub.status.idle": "2023-08-06T12:29:09.111437Z",
     "shell.execute_reply": "2023-08-06T12:29:09.110251Z"
    },
    "papermill": {
     "duration": 0.047521,
     "end_time": "2023-08-06T12:29:09.113591",
     "exception": false,
     "start_time": "2023-08-06T12:29:09.066070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (30, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.191959, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33e5d995",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:09.140783Z",
     "iopub.status.busy": "2023-08-06T12:29:09.139671Z",
     "iopub.status.idle": "2023-08-06T12:29:09.147881Z",
     "shell.execute_reply": "2023-08-06T12:29:09.146961Z"
    },
    "papermill": {
     "duration": 0.023646,
     "end_time": "2023-08-06T12:29:09.149729",
     "exception": false,
     "start_time": "2023-08-06T12:29:09.126083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.15225"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b084077d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:09.176940Z",
     "iopub.status.busy": "2023-08-06T12:29:09.176062Z",
     "iopub.status.idle": "2023-08-06T12:29:09.193536Z",
     "shell.execute_reply": "2023-08-06T12:29:09.192834Z"
    },
    "papermill": {
     "duration": 0.033326,
     "end_time": "2023-08-06T12:29:09.195661",
     "exception": false,
     "start_time": "2023-08-06T12:29:09.162335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca777fc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:09.224795Z",
     "iopub.status.busy": "2023-08-06T12:29:09.223753Z",
     "iopub.status.idle": "2023-08-06T12:29:09.229749Z",
     "shell.execute_reply": "2023-08-06T12:29:09.228580Z"
    },
    "papermill": {
     "duration": 0.022967,
     "end_time": "2023-08-06T12:29:09.231940",
     "exception": false,
     "start_time": "2023-08-06T12:29:09.208973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe89acd4",
   "metadata": {
    "papermill": {
     "duration": 0.012281,
     "end_time": "2023-08-06T12:29:09.256839",
     "exception": false,
     "start_time": "2023-08-06T12:29:09.244558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id = \"5\"></a><br>\n",
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00cbf9d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:09.283838Z",
     "iopub.status.busy": "2023-08-06T12:29:09.283448Z",
     "iopub.status.idle": "2023-08-06T12:29:09.288780Z",
     "shell.execute_reply": "2023-08-06T12:29:09.287303Z"
    },
    "papermill": {
     "duration": 0.021797,
     "end_time": "2023-08-06T12:29:09.291255",
     "exception": false,
     "start_time": "2023-08-06T12:29:09.269458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7577f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:29:09.318902Z",
     "iopub.status.busy": "2023-08-06T12:29:09.317936Z",
     "iopub.status.idle": "2023-08-06T12:38:17.362283Z",
     "shell.execute_reply": "2023-08-06T12:38:17.361410Z"
    },
    "papermill": {
     "duration": 548.066025,
     "end_time": "2023-08-06T12:38:17.369910",
     "exception": false,
     "start_time": "2023-08-06T12:29:09.303885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "368/368 [==============================] - 27s 65ms/step - loss: 2.5207\n",
      "Epoch 2/20\n",
      "368/368 [==============================] - 25s 65ms/step - loss: 1.9864\n",
      "Epoch 3/20\n",
      "368/368 [==============================] - 27s 69ms/step - loss: 1.8244\n",
      "Epoch 4/20\n",
      "368/368 [==============================] - 25s 65ms/step - loss: 1.7362\n",
      "Epoch 5/20\n",
      "368/368 [==============================] - 24s 62ms/step - loss: 1.6804\n",
      "Epoch 6/20\n",
      "368/368 [==============================] - 24s 63ms/step - loss: 1.6409\n",
      "Epoch 7/20\n",
      "368/368 [==============================] - 26s 67ms/step - loss: 1.6121\n",
      "Epoch 8/20\n",
      "368/368 [==============================] - 26s 67ms/step - loss: 1.5894\n",
      "Epoch 9/20\n",
      "368/368 [==============================] - 25s 65ms/step - loss: 1.5716\n",
      "Epoch 10/20\n",
      "368/368 [==============================] - 26s 66ms/step - loss: 1.5571\n",
      "Epoch 11/20\n",
      "368/368 [==============================] - 26s 67ms/step - loss: 1.5446\n",
      "Epoch 12/20\n",
      "368/368 [==============================] - 26s 68ms/step - loss: 1.5349\n",
      "Epoch 13/20\n",
      "368/368 [==============================] - 26s 68ms/step - loss: 1.5256\n",
      "Epoch 14/20\n",
      "368/368 [==============================] - 27s 69ms/step - loss: 1.5177\n",
      "Epoch 15/20\n",
      "368/368 [==============================] - 26s 67ms/step - loss: 1.5109\n",
      "Epoch 16/20\n",
      "368/368 [==============================] - 26s 68ms/step - loss: 1.5048\n",
      "Epoch 17/20\n",
      "368/368 [==============================] - 26s 67ms/step - loss: 1.4991\n",
      "Epoch 18/20\n",
      "368/368 [==============================] - 26s 67ms/step - loss: 1.4940\n",
      "Epoch 19/20\n",
      "368/368 [==============================] - 26s 67ms/step - loss: 1.4895\n",
      "Epoch 20/20\n",
      "368/368 [==============================] - 26s 67ms/step - loss: 1.4853\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf23924",
   "metadata": {
    "papermill": {
     "duration": 0.42124,
     "end_time": "2023-08-06T12:38:18.270373",
     "exception": false,
     "start_time": "2023-08-06T12:38:17.849133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id = \"6\"></a><br>\n",
    "# Extra: Customized Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b33d6f75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:38:19.182265Z",
     "iopub.status.busy": "2023-08-06T12:38:19.181926Z",
     "iopub.status.idle": "2023-08-06T12:38:19.192953Z",
     "shell.execute_reply": "2023-08-06T12:38:19.191412Z"
    },
    "papermill": {
     "duration": 0.501811,
     "end_time": "2023-08-06T12:38:19.195397",
     "exception": false,
     "start_time": "2023-08-06T12:38:18.693586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3044f79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:38:20.042593Z",
     "iopub.status.busy": "2023-08-06T12:38:20.041902Z",
     "iopub.status.idle": "2023-08-06T12:38:20.059999Z",
     "shell.execute_reply": "2023-08-06T12:38:20.058621Z"
    },
    "papermill": {
     "duration": 0.442494,
     "end_time": "2023-08-06T12:38:20.062655",
     "exception": false,
     "start_time": "2023-08-06T12:38:19.620161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "629159f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:38:20.969940Z",
     "iopub.status.busy": "2023-08-06T12:38:20.969589Z",
     "iopub.status.idle": "2023-08-06T12:38:23.175604Z",
     "shell.execute_reply": "2023-08-06T12:38:23.174078Z"
    },
    "papermill": {
     "duration": 2.697709,
     "end_time": "2023-08-06T12:38:23.177608",
     "exception": false,
     "start_time": "2023-08-06T12:38:20.479899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "As your shame in the kings, far shall welcome up there curse her smorts\n",
      "By heavens:\n",
      "I will place opposed of depart most grace a house.\n",
      "\n",
      "GLOUCESTER:\n",
      "We have it as deny leek I aid dream that not.\n",
      "\n",
      "KING LID:\n",
      "Horse forth an it.\n",
      "Now, dilly, God have ambell-begnian good, of Bick'd state?\n",
      "\n",
      "CORIOLANUS:\n",
      "This is ever may, nungly take\n",
      "and\n",
      "hath yea, day your suedd.\n",
      "\n",
      "KING RICHARD III:\n",
      "Loven, whis it is an redous. And her raught they will stay.\n",
      "\n",
      "BENCY:\n",
      "I know the hands all of and Wircure their comfort meanfaly, my lord, if you\n",
      "are unfortune, I have cated, the scelfulled in a kingdow lovey\n",
      "Throubled flower; the days his assess doth means\n",
      "Lordy:\n",
      "A gentleman is blessed kized\n",
      "All a such\n",
      "instrumention so benterspines not baral would love, she kings, nor her time, or it be amoin things like is thyself three any made, good againstly; peace; and you.\n",
      "Is be your strevous may.\n",
      "He not rocks, and not should nevery:\n",
      "Brestielding:\n",
      "But, like you go mer at unwair said withly being straight,\n",
      "And reep.\n",
      "\n",
      "Adwess from, \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 2.196758508682251\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73bc9b4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:38:24.020770Z",
     "iopub.status.busy": "2023-08-06T12:38:24.020399Z",
     "iopub.status.idle": "2023-08-06T12:38:26.119204Z",
     "shell.execute_reply": "2023-08-06T12:38:26.118050Z"
    },
    "papermill": {
     "duration": 2.524398,
     "end_time": "2023-08-06T12:38:26.121848",
     "exception": false,
     "start_time": "2023-08-06T12:38:23.597450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b\"ROMEO:\\nLet unboled.\\n\\nLUCIO:\\nHang effed.\\n\\nSOMEPESBY:\\nWhile all the comence; as gives make the seem\\nSignicangmimas waretwerets of your Aulan:\\nDiskings\\nFrom Engelo, it exprinets he relebs the tribuin.\\n\\nMENEN:\\nWho soon no good death shall be is sweet could, it deturning for and glace of Nortute.\\n\\nROMEO:\\nThe burinatioas, her prozaly friar most one gond it not scarding joy, they are word: but go, for my hadved with your prison'' myst all Welcome.\\nAlazbly brother's so send tryst the hair, ear\\nA right nay your common talk.\\n\\nBUNENELET:\\nOn him.\\n\\nLUCIO:\\nA please in men;\\nBut two, and quutuoul is maidness;\\nFor to cup them. Spalis.\\nHow we well rishards.\\n\\nDUKE VINCENTIO:\\nUpon my weap him cousin's poverty\\nLasting in for the better to Speined before these disuse.\\n\\nKING RICHARD III:\\nI preut.\\n\\nLEONTES:\\nWell I are not be as sland\\nCan a daughter to hephagea!' last\\nIt blood furthing the a$perate.\\nGeforate.\\n\\nLEONTES:\\nAmvan of her that lives with cal where now kiss he not am a pome?\\nHered? Forelack, themperfes at g\"\n",
      " b\"ROMEO:\\nHow, need in part and make an our head:\\nOur show, and all the darch you,\\nThat we have will,\\nCont for hor own sit! Earing betiggs doth thy intent\\nOf vayor: lo'ed:\\nLiol--\\nsir myselve the dasps, convene'd To: and now fear?\\nLet cannot tale in my county him; I\\npriests arm as poinins not fare--\\nThe perunt\\nhour faith to see through steke of Give I pish: I am before\\nHis grace, in first love then I like that I see:\\nBut he swear saw\\nThey armon.\\n\\nSAMILLO:\\nTherewatters do say be a saunted to imagin:\\nWhy, Catishe, I'll denep might over you foul, sir: help we till God in a sullee them look,\\nThe duked ground intertures, lie the morning; he, this bagian:\\nBring in arrow; I ceald, stand his witness.\\n\\nEDWARD:\\nHow now, That not such pray\\nTheir gentleman:\\nYou are subator this they avonders mine's aufis, for a brother talence of their hang, not the else sat it, I am now a being lipness:\\nBut\\na given dishon his person in days dluphil the queen\\nFrom;\\nHence dibly thought and to clofe\\nTo spur\\nthyself; whit not \"\n",
      " b\"ROMEO:\\nNay that sem goped.\\n\\nHORTENSIO:\\nLet stir Bursent speed herishion, God talk heaven among\\nSence\\nAnd coljter, I'll not did so ere you mark thereace for a matterouch genter\\nOf a heaven,\\nAs with me have we promort what very strime do any doubt-call thy daughte:\\nYou thus.\\n\\nANGELO:\\nBut infectimage from news. Behy pay, this fair bready may matured, A\\nhave what have whom awhird to ries the brother have mark\\nTo his pupince kindly witness\\nDid she! O, go the nightion\\nOther, I will said, bright thee?\\n\\nBRUTUS:\\nTaken; one whet you must clade,\\nIt wi'er to so.\\n\\nNurse:\\nI from the mouth his consulf stirr'd you no carrin!\\nYou has be was;\\nThe mare of holy, mine of well, rough I do you go that stause thous, Warge with much rest the beaurfucio you will be him are were I'll trumple of king's let the succession,\\nTo be tennerd\\nAgicle.\\n\\nLord:\\nAnd I say, my lord not fault hunige I ar\\nWirture whereon is Norgoors,\\n'Tis begint\\nThat SAPlaughting courses!\\nBut, as no linged opperious take,\\nAff thou.\\n\\nRICHARD III:\\nCobe\"\n",
      " b\"ROMEO:\\nI will entrys death'd resils will jest Fall,\\nWe she have, myselve merembty in the savide flack in man in a vicate, and a disprace's other?\\n\\nEMEO:\\nGreat letter rebrite?\\n\\nFRIA:\\nWell, and to where a sknow\\nThe loveing well's time to never he harm\\nBe among bid the very tence and have you are knople, my house in\\nThus lefting in words fouls,\\nBoth clowge anvel of Clertions.\\n\\nKING RICHARD III:\\nBelaber from\\nIs not us the doing by you died,\\nAnd shall I shall I had for him very marress opperils.\\n\\nSICINIUS:\\nHer all\\nI hovely 'cive them unmanat, how sleep Sailow:\\nAule\\nme of Londinow for your love, how: as well weep of Richard hindiclact, I haves me: Blood, I let sword is young you the sterm, is he shall besurples this is justiver serve the caren thing and was telllos alous marret of mine for the keep should speriting wis devision,\\nAnd too live, nothing sir; the living and.\\nGrack,\\nBe\\nI;\\nMo.\\nAnd Live we sigh to seem hear not father. What's the entrilloward is the Licknows no run other.\\n\\nLEONTES:\\nThe p\"\n",
      " b\"ROMEO:\\nThe tnouve a consiles something king we forth Persuace,\\nWhere\\nboy I have a should gelo,\\nWhere:\\nYet hath here the baty see a grown me Richard, old of the pervising they, the feart,\\nWhen I did one so report was good soul thinds, pleaning and his sorry his meriare--\\nAs the emforth toogor.\\n\\nSecond Murderous clolded thine, it is burne.\\n\\nHORTENSIO:\\nWe look,\\nThou to go bent tires of you, ellow him; she weem portinaram as he had not your bloods.\\nMether you erefuile?\\n\\nEXES:\\nConsul's acconingers.\\nWell.\\n\\nDUCHESS, shall you wilt us this could be shall mouse sage\\nYour eal,\\nLet make;\\nThat let him\\nFran mointly cleed than the death,\\nThe changed,\\nWhy,\\nI cried?\\n\\nKING RICHARD II:\\nWhat I am hence, and hocks ruignes jest tears a molt him! servicion on face to be faptor. Countio compleit in my lords.\\n\\nKING RICHARD III:\\nYet digly brother's, look twentwer this gived\\nThe nother; or withmen, thou bead you?\\nEven we pate\\nus my shaw her im:\\nShe hath he services, CoRARET:\\nYour fake the right by them to and a dast \"], shape=(5,), dtype=string) \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 2.0868794918060303\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result, '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1896024a",
   "metadata": {
    "papermill": {
     "duration": 0.481028,
     "end_time": "2023-08-06T12:38:27.036632",
     "exception": false,
     "start_time": "2023-08-06T12:38:26.555604",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7011637",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:38:27.883494Z",
     "iopub.status.busy": "2023-08-06T12:38:27.882421Z",
     "iopub.status.idle": "2023-08-06T12:38:27.888399Z",
     "shell.execute_reply": "2023-08-06T12:38:27.887721Z"
    },
    "papermill": {
     "duration": 0.432305,
     "end_time": "2023-08-06T12:38:27.890633",
     "exception": false,
     "start_time": "2023-08-06T12:38:27.458328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomTraining(MyModel):\n",
    "  @tf.function\n",
    "  def train_step(self, inputs):\n",
    "      inputs, labels = inputs\n",
    "      with tf.GradientTape() as tape:\n",
    "          predictions = self(inputs, training=True)\n",
    "          loss = self.loss(labels, predictions)\n",
    "      grads = tape.gradient(loss, model.trainable_variables)\n",
    "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "      return {'loss': loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84a0263c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:38:28.797499Z",
     "iopub.status.busy": "2023-08-06T12:38:28.797113Z",
     "iopub.status.idle": "2023-08-06T12:38:28.811560Z",
     "shell.execute_reply": "2023-08-06T12:38:28.810587Z"
    },
    "papermill": {
     "duration": 0.503184,
     "end_time": "2023-08-06T12:38:28.813995",
     "exception": false,
     "start_time": "2023-08-06T12:38:28.310811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CustomTraining(\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed8d31d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:38:29.655641Z",
     "iopub.status.busy": "2023-08-06T12:38:29.655267Z",
     "iopub.status.idle": "2023-08-06T12:38:29.665259Z",
     "shell.execute_reply": "2023-08-06T12:38:29.663935Z"
    },
    "papermill": {
     "duration": 0.434681,
     "end_time": "2023-08-06T12:38:29.667600",
     "exception": false,
     "start_time": "2023-08-06T12:38:29.232919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0fd51e90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:38:30.576397Z",
     "iopub.status.busy": "2023-08-06T12:38:30.575562Z",
     "iopub.status.idle": "2023-08-06T12:38:57.674484Z",
     "shell.execute_reply": "2023-08-06T12:38:57.673702Z"
    },
    "papermill": {
     "duration": 27.585521,
     "end_time": "2023-08-06T12:38:57.676282",
     "exception": false,
     "start_time": "2023-08-06T12:38:30.090761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 27s 66ms/step - loss: 2.5136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x78c4997bcdf0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e14ef189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T12:38:58.562773Z",
     "iopub.status.busy": "2023-08-06T12:38:58.561888Z",
     "iopub.status.idle": "2023-08-06T12:43:17.038841Z",
     "shell.execute_reply": "2023-08-06T12:43:17.037397Z"
    },
    "papermill": {
     "duration": 258.922602,
     "end_time": "2023-08-06T12:43:17.041266",
     "exception": false,
     "start_time": "2023-08-06T12:38:58.118664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.1435\n",
      "Epoch 1 Batch 50 Loss 2.0841\n",
      "Epoch 1 Batch 100 Loss 2.0383\n",
      "Epoch 1 Batch 150 Loss 2.0098\n",
      "Epoch 1 Batch 200 Loss 1.9637\n",
      "Epoch 1 Batch 250 Loss 1.9465\n",
      "Epoch 1 Batch 300 Loss 1.9377\n",
      "Epoch 1 Batch 350 Loss 1.8942\n",
      "\n",
      "Epoch 1 Loss: 1.9892\n",
      "Time taken for 1 epoch 26.49 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 2 Batch 0 Loss 1.8623\n",
      "Epoch 2 Batch 50 Loss 1.8902\n",
      "Epoch 2 Batch 100 Loss 1.8546\n",
      "Epoch 2 Batch 150 Loss 1.8609\n",
      "Epoch 2 Batch 200 Loss 1.7816\n",
      "Epoch 2 Batch 250 Loss 1.8320\n",
      "Epoch 2 Batch 300 Loss 1.8073\n",
      "Epoch 2 Batch 350 Loss 1.7784\n",
      "\n",
      "Epoch 2 Loss: 1.8297\n",
      "Time taken for 1 epoch 25.53 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 3 Batch 0 Loss 1.7638\n",
      "Epoch 3 Batch 50 Loss 1.7624\n",
      "Epoch 3 Batch 100 Loss 1.7106\n",
      "Epoch 3 Batch 150 Loss 1.7461\n",
      "Epoch 3 Batch 200 Loss 1.7173\n",
      "Epoch 3 Batch 250 Loss 1.7021\n",
      "Epoch 3 Batch 300 Loss 1.7301\n",
      "Epoch 3 Batch 350 Loss 1.6876\n",
      "\n",
      "Epoch 3 Loss: 1.7405\n",
      "Time taken for 1 epoch 25.93 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 4 Batch 0 Loss 1.7250\n",
      "Epoch 4 Batch 50 Loss 1.7010\n",
      "Epoch 4 Batch 100 Loss 1.6768\n",
      "Epoch 4 Batch 150 Loss 1.6541\n",
      "Epoch 4 Batch 200 Loss 1.6854\n",
      "Epoch 4 Batch 250 Loss 1.6888\n",
      "Epoch 4 Batch 300 Loss 1.6982\n",
      "Epoch 4 Batch 350 Loss 1.6676\n",
      "\n",
      "Epoch 4 Loss: 1.6837\n",
      "Time taken for 1 epoch 26.15 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 5 Batch 0 Loss 1.7654\n",
      "Epoch 5 Batch 50 Loss 1.6578\n",
      "Epoch 5 Batch 100 Loss 1.6316\n",
      "Epoch 5 Batch 150 Loss 1.6141\n",
      "Epoch 5 Batch 200 Loss 1.6587\n",
      "Epoch 5 Batch 250 Loss 1.6636\n",
      "Epoch 5 Batch 300 Loss 1.6012\n",
      "Epoch 5 Batch 350 Loss 1.6657\n",
      "\n",
      "Epoch 5 Loss: 1.6443\n",
      "Time taken for 1 epoch 25.71 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 6 Batch 0 Loss 1.6223\n",
      "Epoch 6 Batch 50 Loss 1.6326\n",
      "Epoch 6 Batch 100 Loss 1.6452\n",
      "Epoch 6 Batch 150 Loss 1.6837\n",
      "Epoch 6 Batch 200 Loss 1.6270\n",
      "Epoch 6 Batch 250 Loss 1.5601\n",
      "Epoch 6 Batch 300 Loss 1.6666\n",
      "Epoch 6 Batch 350 Loss 1.5363\n",
      "\n",
      "Epoch 6 Loss: 1.6154\n",
      "Time taken for 1 epoch 25.82 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 7 Batch 0 Loss 1.5369\n",
      "Epoch 7 Batch 50 Loss 1.6017\n",
      "Epoch 7 Batch 100 Loss 1.5898\n",
      "Epoch 7 Batch 150 Loss 1.5850\n",
      "Epoch 7 Batch 200 Loss 1.5448\n",
      "Epoch 7 Batch 250 Loss 1.5779\n",
      "Epoch 7 Batch 300 Loss 1.5719\n",
      "Epoch 7 Batch 350 Loss 1.5533\n",
      "\n",
      "Epoch 7 Loss: 1.5932\n",
      "Time taken for 1 epoch 25.97 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 8 Batch 0 Loss 1.5721\n",
      "Epoch 8 Batch 50 Loss 1.6055\n",
      "Epoch 8 Batch 100 Loss 1.5471\n",
      "Epoch 8 Batch 150 Loss 1.6542\n",
      "Epoch 8 Batch 200 Loss 1.5453\n",
      "Epoch 8 Batch 250 Loss 1.6052\n",
      "Epoch 8 Batch 300 Loss 1.6023\n",
      "Epoch 8 Batch 350 Loss 1.5792\n",
      "\n",
      "Epoch 8 Loss: 1.5752\n",
      "Time taken for 1 epoch 25.45 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 9 Batch 0 Loss 1.5674\n",
      "Epoch 9 Batch 50 Loss 1.5699\n",
      "Epoch 9 Batch 100 Loss 1.5643\n",
      "Epoch 9 Batch 150 Loss 1.5969\n",
      "Epoch 9 Batch 200 Loss 1.6035\n",
      "Epoch 9 Batch 250 Loss 1.5614\n",
      "Epoch 9 Batch 300 Loss 1.5383\n",
      "Epoch 9 Batch 350 Loss 1.5751\n",
      "\n",
      "Epoch 9 Loss: 1.5608\n",
      "Time taken for 1 epoch 25.49 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 10 Batch 0 Loss 1.5706\n",
      "Epoch 10 Batch 50 Loss 1.4781\n",
      "Epoch 10 Batch 100 Loss 1.5170\n",
      "Epoch 10 Batch 150 Loss 1.4809\n",
      "Epoch 10 Batch 200 Loss 1.5925\n",
      "Epoch 10 Batch 250 Loss 1.6003\n",
      "Epoch 10 Batch 300 Loss 1.5367\n",
      "Epoch 10 Batch 350 Loss 1.5604\n",
      "\n",
      "Epoch 10 Loss: 1.5486\n",
      "Time taken for 1 epoch 25.90 sec\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "mean = tf.metrics.Mean()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    mean.reset_states()\n",
    "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
    "        logs = model.train_step([inp, target])\n",
    "        mean.update_state(logs['loss'])\n",
    "\n",
    "        if batch_n % 50 == 0:\n",
    "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
    "            print(template)\n",
    "\n",
    "    # saving (checkpoint) the model every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
    "\n",
    "    print()\n",
    "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
    "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
    "    print(\"_\"*80)\n",
    "\n",
    "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 873.997482,
   "end_time": "2023-08-06T12:43:20.335047",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-06T12:28:46.337565",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
